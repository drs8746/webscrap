{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download html files from bis.org central banker speech site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access BIS speech site\n",
    "driver.get(\"https://www.bis.org/cbspeeches/index.htm?m=2%7C10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_page = driver.find_elements(By.XPATH, \"//div[@class='pageof']\")[0]\n",
    "tot_page = tot_page.find_elements_by_css_selector(\"*\")\n",
    "tot_page = int(bar2.text.split(' ')[-1].replace(',', ''))\n",
    "tot_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#download folder\n",
    "down_folder = r'..\\data\\bisorg_cbspeech'\n",
    "Path(down_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th page downloaded\n"
     ]
    }
   ],
   "source": [
    "for i in range(tot_page):    \n",
    "    _datapage = driver.find_elements(By.XPATH, \"//a[@data-page]\")[-1]\n",
    "    _html = str.encode(driver.page_source)\n",
    "    _filename = 'p{0}.html.txt'.format(10000+i)\n",
    "    with open(os.path.join(down_folder,_filename),'wb') as fout:\n",
    "        fout.write(_html)\n",
    "    _datapage.click()\n",
    "    time.sleep(3)\n",
    "    if i % 100 == 0:\n",
    "        print('{0}th page downloaded'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract link from above html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlfiles=os.listdir(down_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech_list(htmlfile):\n",
    "    \n",
    "    soup = bs4.BeautifulSoup(open(os.path.join(down_folder,htmlfiles[0]), 'rb').read().decode())\n",
    "    content = soup.find(\"table\",{\"class\":\"documentList\"})\n",
    "    \n",
    "    speeches = list()\n",
    "    for i in content.find_all('tr'):\n",
    "        try:\n",
    "            dict_speech = dict()\n",
    "            dict_speech['date'] = i.find(\"td\",{\"class\":\"item_date\"}).text.strip()\n",
    "            dict_speech['link'] = i.find(\"a\")['href'].strip()\n",
    "            dict_speech['title'] = i.find(\"a\").text.strip()\n",
    "            dict_speech['info'] = i.find(\"div\",{\"class\",\"info\"}).text.strip().split('\\n')[0]\n",
    "        except Exception as e:\n",
    "            print('Error({0}): {1}'.format(i,e))\n",
    "            break\n",
    "        speeches.append(dict_speech)\n",
    "    \n",
    "    return speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_speech = dict()\n",
    "for htmlfile in htmlfiles:\n",
    "    dict_speech[htmlfile] = generate_speech_list(htmlfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download a speech html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bis = r\"https://www.bis.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta(meta_tags):\n",
    "    dict_meta = dict()\n",
    "    for i in meta_tags:\n",
    "        if i.has_attr('name'):\n",
    "            if i['name'] == 'viewport': #It is not related to Content meta\n",
    "                continue\n",
    "            else:\n",
    "                dict_meta[i['name']] = i['content']\n",
    "    return dict_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _key in dict_speech:\n",
    "    for _speech in dict_speech[_key]:\n",
    "        soup = bs4.BeautifulSoup(requests.get(url_bis+_speech['link']).content.decode()) \n",
    "        _speech['meta'] = extract_meta(soup.find_all(\"meta\"))\n",
    "        _speech['content'] = soup.find(\"div\",{\"id\":\"cmsContent\"}).text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('env': venv)",
   "language": "python",
   "name": "python37464bitenvvenvf03e7c7b497042ccb9165810c3007ade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
