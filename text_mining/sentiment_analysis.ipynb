{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reference: https://towardsdatascience.com/basic-binary-sentiment-analysis-using-nltk-c94ba17ae386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(my_key, my_query,from_date,to_date):\n",
    "    newsapi = NewsApiClient(api_key=my_key)\n",
    "\n",
    "    all_articles = newsapi.get_everything(q=my_query,\n",
    "                                          from_param=from_date,\n",
    "                                          to=to_date,\n",
    "                                          language='en',\n",
    "                                          sort_by='relevancy',\n",
    "                                          page=5)\n",
    "    return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 20, 15, 11, 38, 724384)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_date = datetime.datetime.now()\n",
    "to_date = from_date - datetime.timedelta(30)\n",
    "from_date = from_date.strftime('%Y-%m-%d')\n",
    "to_date = to_date.strftime('%Y-%m-%d')\n",
    "my_query = 'coronavirus'\n",
    "all_articles = get_news('',my_query,from_date,to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(my_query + '_news.json','w') as fout:\n",
    "    json.dump(all_articles,fout)\n",
    "\n",
    "# Load the content from json file\n",
    "with open (my_query + '_news.json','r') as fin:\n",
    "    all_articles = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(article):\n",
    "    res_str = ''\n",
    "    for _key in ['title','description','content']:\n",
    "        _str = article[_key]\n",
    "        if _str is not None:\n",
    "            if _str.find('…') > 0:\n",
    "                _str = _str[:_str.find('…')]\n",
    "            res_str += _str + '. '  \n",
    "        else:\n",
    "            continue\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_article = dict()\n",
    "for article in all_articles['articles']:\n",
    "    yyyymmdd = pd.to_datetime(article['publishedAt']).strftime('%Y%m%d')\n",
    "    if dict_article.get(yyyymmdd):\n",
    "        dict_article[yyyymmdd].append(extract_content(article))\n",
    "    else:\n",
    "        dict_article[yyyymmdd] =[extract_content(article)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ' '.join([i[0] for i in dict_article.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content.replace('\\r\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence seperation\n",
    "cleaned_sent =[remove_punctuation(sentence) for sentence in sent_tokenize(content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word extraction\n",
    "speech_words = [word_tokenize(sentence) for sentence in cleaned_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(sentence):\n",
    "    return [w for w in sentence if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [remove_stopword(s) for s in speech_words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = [nltk.pos_tag(_word) for _word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
